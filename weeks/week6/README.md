## Week 6: Local Models & Fine-tuning

### Running Local LLMs
- Introduction to open-source LLMs (Llama)
- Model weights and formats (GGUF, Safetensors)
- Quantization concepts and tradeoffs
- Setting up llama.cpp for local inference
- Using Hugging Face Transformers for local inference
- Local model servers (vLLM, Ollama)
- Performance optimization for local deployment
- Comparing local models vs. API-based models

### Fine-tuning LLMs
- When and why to fine-tune
- Parameter-efficient fine-tuning (PEFT) methods
- LoRA and QLoRA techniques
- Instruction tuning with public datasets
- Evaluating fine-tuned models
- Maintaining alignment during fine-tuning
- Deploying fine-tuned models

### Datasets
- [financial sentiment](https://huggingface.co/datasets/takala/financial_phrasebank)
- [SAMSum](https://huggingface.co/datasets/Samsung/samsum)

### Theory, Courses & Additional Reading
- [paper: LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971)
- [paper: Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/pdf/2307.09288)
- [paper: The Case for 4-bit Precision: k-bit Inference Scaling Laws](https://arxiv.org/pdf/2212.09720)
- [paper: Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416)
- [paper: LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685)
- [paper: QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/pdf/2305.14314)
- [course: Open Source Models with Hugging Face](https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/)
- [course: Prompt Engineering with Llama 2 & 3](https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/)
- [course: Finetuning Large Language Models](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)
- [course: Fine-tune Large Language Models](https://huggingface.co/learn/nlp-course/chapter11)

### Assignments:
**Assignment 1: Local LLM Deployment**

Specific Task:  Set up and explore a local LLM for inference

Deliverables:

- Working installation of llama.cpp with LLama 3 Instruct model
- Basic benchmarking at one or two quantization levels
- Simple web UI for interacting with the model

Success Criteria: Successfully run the model locally and generate coherent responses, with documentation of generation speed

**Assignment 2: Fine-tuning with LoRA**

Specific Task: Fine-tune a small language model for a specific task (sentiment analysis or conversation summarization)

Deliverables:

- LoRA fine-tuning script for a 3B - 7B parameter model (e.g. Llama 3.1)
- Comparison of pre-fine-tuning vs. post-fine-tuning performance
- Simple demo showing the improvement in the targeted capability
- Report with the fine-tuning process and results

Success Criteria: Complete a LoRA fine-tuning process and demonstrate any improvement on the target task